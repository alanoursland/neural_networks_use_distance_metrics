\section{Background}

In our previous work, \textit{Interpreting Neural Networks through Mahalanobis Distance} \citep{oursland2024interpreting}, we established a mathematical link between linear nodes with absolute value activation functions and statistical distance metrics. This framework suggests that neural networks may naturally learn to measure distances rather than intensities, though empirical validation is necessary to confirm whether networks indeed employ distance-based computations.

We explore these ideas within the MNIST dataset \citep{lecun1998gradient}, a well-known digit recognition problem that offers a structured environment for examining neural network behavior. MNIST's clear feature structure and abundant prior research make it ideal for investigating core properties of neural network learning.

A \emph{distance metric} quantifies how far an input is from a learned statistical property of the data \citep{deza2009encyclopedia}, while an \emph{intensity metric} reflects a confidence level—larger values indicate higher certainty that the input belongs to the node's feature set. This dual interpretation of a node's output—either as a measure of distance or as confidence in feature presence—can help us understand the nature of neural network learning. For instance, an intensity filter could be viewed as a \emph{disjunctive distance metric} that measures how close an input is to everything the target feature is not.

\subsection{From Theory to Practice}

The distinction between distance and intensity metrics becomes critical when analyzing network behavior. Traditional interpretations suggest that the node detects the “presence of 0,” with higher activation values indicating greater confidence. However, another possibility is that the node measures the “distance from class embeddings that are not 0” — i.e., how different the input is from all other digits. Both interpretations lead to the same result, but the disjunctive distance-based view aligns more closely with known statistical distance metrics. While there may be statistical intensity metrics, the authors have yet to identify one that models confidence signals in the same way.

This reframing suggests that neural networks might fundamentally operate by \emph{comparing inputs to learned prototypes} rather than \emph{assessing the strength of individual features}. However, proving this requires more than mathematical relationships; we need empirical evidence that networks indeed learn and use distance metrics in practice. This leads to several key questions:

\begin{itemize}
    \item Do neural networks naturally learn to measure distances rather than intensities?
    \item How can we experimentally distinguish between distance-based and intensity-based feature learning?
    \item What evidence would convincingly demonstrate which interpretation better reflects network operation?
\end{itemize}

These questions inform our experimental design, which uses controlled perturbations to test the nature of the learned features. By independently manipulating the distance and intensity properties of network activations, we can determine which aspects truly drive network behavior.

Our investigation focuses not on proving specific mathematical relationships but on demonstrating that \emph{distance-based properties}, rather than \emph{intensity-based properties}, govern network performance. This approach aims to improve our understanding of how neural networks process information and may lead to more effective network design and analysis methods \citep{montavon2018methods, samek2019explainable}.