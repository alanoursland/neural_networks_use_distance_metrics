\section{Background}

Neural networks have predominantly been interpreted as generating statistical intensity metrics since Rosenblatt published \textit{Perceptrons: An Introduction to Computational Geometry} in 1958. Under this interpretation, larger activation values indicate stronger feature presence or higher confidence in feature detection. While this approach has driven many successes, connecting individual node activations to clear statistical properties of data has remained challenging.

\subsection{Theoretical Foundation}

In our previous work, \textit{Interpreting Neural Networks through Mahalanobis Distance} \citep{oursland2024interpreting}, we established a mathematical link between linear nodes with absolute value activation functions and statistical distance metrics. This framework suggests that neural networks may naturally learn to measure distances rather than intensities, though empirical validation is necessary to confirm whether networks indeed employ distance-based computations.

A **distance metric** quantifies how far an input is from a learned statistical property of the data, while an **intensity metric** reflects a confidence level—larger values indicate higher certainty that the input belongs to the node's feature set. This dual interpretation of a node’s output—either as a measure of distance or as confidence in feature presence—can help us understand the nature of neural network learning. For instance, an intensity filter could be viewed as a disjunctive distance metric, measuring how close an input is to everything the feature does not recognize.

We explore these ideas within the MNIST dataset, a well-known digit recognition problem that offers a structured environment for examining neural network behavior. MNIST's clear feature structure and abundant prior research make it ideal for investigating core properties of neural network learning.

Consider a neural network node trained on MNIST. Traditional interpretations suggest that the node detects the “presence of 0,” with higher activation values indicating greater confidence. However, another possibility is that the node measures the “distance from class embeddings that are not 0”—i.e., how different the input is from all other digits. Both interpretations can lead to successful classification, but the distance-based view aligns more closely with known statistical distance metrics. While there may be statistical intensity metrics, the authors have yet to identify one that models confidence signals in the same way.

\subsection{From Theory to Practice}

The distinction between distance and intensity metrics becomes critical when analyzing network behavior. Our investigation addresses whether neural networks learn distance metrics or intensity metrics as they process data. For example, in the MNIST context, we could define a disjunctive feature that accepts digits 1-9 and rejects 0. In terms of intensity, a high activation would indicate strong confidence in seeing a 0, but this may not correspond to any stable statistical property of the data.

This reframing suggests that neural networks might fundamentally operate as **distance-measuring devices** rather than **feature detectors**. However, proving this requires more than mathematical relationships; we need empirical evidence that networks indeed learn and use distance metrics in practice. This leads to several key questions:

\begin{itemize}
    \item Do neural networks naturally learn to measure distances rather than intensities?
    \item How can we experimentally distinguish between distance-based and intensity-based feature learning?
    \item What evidence would convincingly demonstrate which interpretation better reflects network operation?
\end{itemize}

These questions inform our experimental design, which uses controlled perturbations to test the nature of the learned features. By independently manipulating the distance and intensity properties of network activations, we can determine which aspects truly drive network behavior.

Our investigation focuses not on proving specific mathematical relationships but on demonstrating that **distance-based properties**, rather than **intensity-based properties**, govern network performance. This approach aims to improve our understanding of how neural networks process information and may lead to more effective network design and analysis methods.
