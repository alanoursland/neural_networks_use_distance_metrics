\section{Introduction}

Neural networks have achieved remarkable success across diverse applications, yet their interpretability remains a significant challenge. Recent theoretical work has proposed a novel framework connecting neural network architectures to the Mahalanobis distance \cite{oursland2024interpreting}, suggesting that individual neurons can be understood as learning statistical distances from prototypical features. While this theoretical connection offers promising insights into neural network interpretation, empirical validation is crucial to establish its practical relevance and implications.

The Mahalanobis distance framework proposes that linear layers with absolute value activations can be interpreted as approximating principal components of Gaussian distributions, with each neuron computing a distance from a learned prototype. This perspective challenges the traditional view of neural network activations as purely intensity-based feature detectors and suggests a more nuanced interpretation based on statistical distance metrics.

Consider a linear layer with weights $W$ and bias $b$, followed by an absolute value activation:
\begin{equation}
    y = |Wx + b|
\end{equation}
The theoretical framework suggests this can be rewritten as:
\begin{equation}
    y = |\lambda^{-1/2}_i v^T_i(x - \mu)|
\end{equation}
where $v_i$ is a principal component direction, $\lambda_i$ is its corresponding eigenvalue, and $\mu$ is the prototype (mean) for that feature. This formulation directly connects neural network computations to statistical distances in the input space.

Our work provides empirical validation of this theoretical connection through systematic perturbation analysis. We investigate two fundamental types of perturbations:
\begin{enumerate}
    \item \textit{Intensity perturbations} that scale the activation magnitude:
        \begin{equation}
            y = (1 + \alpha)|Wx + b|
        \end{equation}
    \item \textit{Distance perturbations} that shift the decision boundary:
        \begin{equation}
            y = |Wx + b + \delta|
        \end{equation}
\end{enumerate}

If neurons indeed learn statistical distances, we expect specific patterns in their response to these perturbations. Distance-based features should be invariant to intensity scaling but highly sensitive to boundary shifts, while traditional intensity-based features would show different characteristics. We examine these predictions through careful empirical analysis of networks trained on the MNIST dataset, comparing absolute value and ReLU activations.

Our investigation addresses three key research questions:
\begin{enumerate}
    \item How do different activation functions respond to intensity versus distance perturbations, and do these responses align with theoretical predictions?
    \item What evidence do perturbation responses provide about the underlying feature representations learned by neural networks?
    \item How can insights from distance-based interpretation improve neural network design and training?
\end{enumerate}

The implications of validating this theoretical framework extend beyond interpretation. Understanding neurons as distance metrics could inform better initialization strategies, suggest new architectures optimized for distance-based learning, and provide principled approaches to feature visualization and network analysis. Additionally, this perspective offers a bridge between neural networks and classical statistical methods, potentially enabling new hybrid approaches that combine the strengths of both paradigms.

This paper makes the following contributions:
\begin{itemize}
    \item Provides comprehensive empirical validation of the theoretical connection between neural networks and Mahalanobis distance
    \item Demonstrates distinctive perturbation response patterns that support interpretation of neurons as distance metrics
    \item Offers practical insights for neural network design based on empirical findings
    \item Establishes a methodology for analyzing neural networks through systematic perturbation analysis
\end{itemize}

The remainder of this paper is organized as follows. Section 2 details our experimental design, including model architectures and perturbation methods. Section 3 presents our empirical results and analysis. Section 4 discusses the implications of our findings and suggests practical applications. Finally, Section 5 concludes with a summary of insights and directions for future research.