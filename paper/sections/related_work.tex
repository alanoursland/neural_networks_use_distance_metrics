\section{Prior Work}

In 1943 McCulloch and Pitt introduced a computation model of a neuron to explore logical equations in biological brains. \citep{mcculloch1943logical} Their definition $TRUE = (Wx > b)$ marks the beginning our path using intensity metrics. Rosenblatt adapted this into an activation value $y = f(Wx + b$) in 1957 with the perceptron, further solidifying the intensity metric interpretation. \citep{rosenblatt1957perceptron} 

The development of multilayer perceptrons (MLPs) and the backpropagation algorithm \citep{rumelhart1986learning} enabled the training of deeper networks with continuous activation functions. \citep{lecun1989backpropagation,hornik1989multilayer} While the development of deeper networks with continuous activation functions opened up new possibilities for representation learning, the interpretation of activations often still focused on larger values as being more salient. This was reflected in visualizations of activations and analyses of feature maps, where stronger activations were highlighted. \citep{zeiler2014visualizing,yosinski2015understanding, olah2017feature, erhan2009visualizing}

The rise of deep learning, with the widespread adoption of ReLU and its variants \citep{nair2010rectified,glorot2011deep}, further reinforced the intensity metric interpretation by emphasizing the importance of large, positive activations. Visualization techniques, such as saliency maps \citep{simonyan2013deep} and Class Activation Mapping (CAM) \citep{zhou2016learning}, often focused on highlighting regions with high activations. Similarly, attention mechanisms, which assign weights to different parts of the input \citep{bahdanau2014neural,vaswani2017attention}, often rely on the magnitude of these weights as indicators of importance. 

While the intensity metric interpretation has been dominant, recent work has highlighted its limitations. \citep{rudin2019stop} Considering the relationships between activations, particularly through distance metrics, offers a promising avenue for understanding neural network representations. \citep{goodfellow2014explaining,madry2017towards,szegedy2013intriguing} Distance-based methods, such as Radial Basis Function (RBF) networks \citep{broomhead1988radial} and Siamese networks \citep{bromley1994signature,schroff2015facenet}, demonstrate the potential of incorporating distance computations into neural network architectures and interpretation. This approach could lead to more nuanced and effective representations, offering a more effective approach to feature representation and learning.
