We present empirical evidence that neural networks with ReLU and Absolute Value activations learn distance-based representations. We perturbed trained models by independently manipulating distance and intensity properties of internal activations. Both architectures are highly sensitive to distance-based perturbations while maintaining robust performance under intensity perturbations. These findings challenge traditional interpretations of neural network activations and offer new insights into their learning and decision-making processes.
